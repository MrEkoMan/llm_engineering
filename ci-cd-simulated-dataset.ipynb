import pandas as pd
import numpy as np
import random
from datetime import datetime, timedelta

# Configuration
np.random.seed(42)
random.seed(42)
authors = ["casey.nguyen", "alex.jordan", "riley.patel", "taylor.murphy", "morgan.lee", "jamie.kim", "avery.clark"]
repo_name = "aws-retail-analytics"
n_pipelines = 1000
n_fail = n_pipelines // 2
n_success = n_pipelines - n_fail

end_time = datetime(2025, 11, 8, 17, 0, 0)
start_times = [end_time - timedelta(minutes=random.randint(10, 90)) for _ in range(n_pipelines)]

data = []
for i in range(n_pipelines):
    start = start_times[i]
    duration = random.randint(300, 1800)
    end = start + timedelta(seconds=duration)
    author = random.choice(authors)
    success = i < n_success
    branch_type = random.choices(["main", "feature/", "bugfix/"], [0.4, 0.45, 0.15])[0]
    branch = branch_type + ("" if branch_type == "main" else random.choice(["checkout", "cart", "auth", "ui", "refactor"]))
    commit_id = ''.join(random.choices('abcdef0123456789', k=12))
    trigger = random.choice(["push", "pull_request", "schedule"])
    environment = random.choice(["dev", "staging", "prod"])
    runner = random.choice(["EC2", "Fargate", "CodeBuild-managed", "Self-hosted"])
    build_reason = random.choice(["Code change", "Dependency update", "Scheduled build"])

    num_tests_run = random.randint(150, 400)
    num_tests_failed = random.randint(0, 10) if success else random.randint(5, 60)
    lines_changed = abs(int(np.random.normal(250, 200)))
    files_changed = max(1, int(np.random.normal(6, 4)))
    dependency_change = random.random() < 0.2
    test_coverage_delta = round(np.random.normal(0, 2), 2)
    flakiness_score = abs(np.random.normal(0.05, 0.03))
    total_stage_count = random.choice([3, 4, 5])
    queue_time_seconds = random.randint(5, 90)
    checkout_duration_seconds = random.randint(20, 60)
    artifact_upload_duration_seconds = random.randint(30, 120)
    previous_status = random.choice(["Succeeded", "Failed"])
    time_since_last_run_hours = round(np.random.uniform(0.5, 24.0), 2)

    # Additional DORA + AI context
    retry_count = random.randint(0, 3) if not success else random.randint(0, 1)
    cache_hit_rate = round(random.uniform(0.5, 1.0), 2)
    artifact_size_mb = round(np.random.normal(250, 80), 2)
    infra_provision_time = random.randint(30, 120)
    deployment_method = random.choice(["Blue/Green", "Canary", "Rolling", "Manual Approval"])
    developer_experience_level = random.choice(["Junior", "Mid", "Senior"])
    day_of_week = start.strftime("%A")
    hour_of_day = start.hour
    pr_cycle_time_hours = round(abs(np.random.normal(12, 8)), 2)
    review_approval_count = random.randint(1, 3)
    commit_message_length = random.randint(20, 120)
    static_analysis_issues = abs(int(np.random.normal(10, 8)))
    flaky_test_count = random.randint(0, 5)
    cyclomatic_complexity_delta = round(np.random.normal(0, 1.5), 2)
    failure_category = random.choice(["test_failure", "infra_issue", "merge_conflict", "timeout", "deployment_error"]) if not success else "none"
    pipeline_definition_version = f"v{random.randint(1,5)}"
    suggested_action = random.choice(["Increase test retries", "Optimize build caching", "Reduce test flakiness", "Review dependencies", "Check infra config"]) if not success else "none"

    data.append({
        "pipeline_execution_id": f"pl-{i+1:04d}-{commit_id[:6]}",
        "repository_name": repo_name,
        "branch": branch,
        "commit_id": commit_id,
        "author": author,
        "trigger_event": trigger,
        "start_time": start,
        "end_time": end,
        "duration_seconds": duration,
        "build_stage_duration": random.randint(100, 600),
        "test_stage_duration": random.randint(80, 500),
        "deploy_stage_duration": random.randint(60, 300),
        "environment": environment,
        "runner_type": runner,
        "status": "Succeeded" if success else "Failed",
        "build_reason": build_reason,
        "num_tests_run": num_tests_run,
        "num_tests_failed": num_tests_failed,
        "lines_changed": lines_changed,
        "files_changed": files_changed,
        "dependency_change": dependency_change,
        "test_coverage_delta": test_coverage_delta,
        "flakiness_score": flakiness_score,
        "total_stage_count": total_stage_count,
        "queue_time_seconds": queue_time_seconds,
        "checkout_duration_seconds": checkout_duration_seconds,
        "artifact_upload_duration_seconds": artifact_upload_duration_seconds,
        "previous_pipeline_status": previous_status,
        "time_since_last_run_hours": time_since_last_run_hours,
        "retry_count": retry_count,
        "cache_hit_rate": cache_hit_rate,
        "artifact_size_mb": artifact_size_mb,
        "infra_provision_time": infra_provision_time,
        "deployment_method": deployment_method,
        "developer_experience_level": developer_experience_level,
        "day_of_week": day_of_week,
        "hour_of_day": hour_of_day,
        "pr_cycle_time_hours": pr_cycle_time_hours,
        "review_approval_count": review_approval_count,
        "commit_message_length": commit_message_length,
        "static_analysis_issues": static_analysis_issues,
        "flaky_test_count": flaky_test_count,
        "cyclomatic_complexity_delta": cyclomatic_complexity_delta,
        "failure_category": failure_category,
        "pipeline_definition_version": pipeline_definition_version,
        "suggested_action": suggested_action
    })

df = pd.DataFrame(data)
df.to_csv("ci_cd_simulation_enriched_1000.csv", index=False)
print("âœ… Dataset saved as ci_cd_simulation_enriched_1000.csv")
