{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "839cd51c",
   "metadata": {},
   "source": [
    "# SAT Outlier Detection & Fairness Impact\n",
    "\n",
    "This notebook simulates a college admissions / donor prediction scenario.\n",
    "We will:\n",
    "1. Generate a synthetic dataset with SAT scores, family income, and a donor label.\n",
    "2. Detect SAT score outliers.\n",
    "3. Train a simple predictive model using all data.\n",
    "4. Compare this to a model trained after removing SAT outliers.\n",
    "5. Evaluate basic **fairness impacts** for an advantaged vs. disadvantaged group.\n",
    "\n",
    "The goal is not to build a perfect model, but to *illustrate* how handling SAT outliers can\n",
    "affect both performance and fairness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2160f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(42)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc71288",
   "metadata": {},
   "source": [
    "## 1. Simulate a Synthetic Dataset\n",
    "\n",
    "We simulate applicants from two groups:\n",
    "- `group = 0`: Disadvantaged (on average lower income, lower SAT)\n",
    "- `group = 1`: Advantaged (on average higher income, higher SAT)\n",
    "\n",
    "We then define a `future_donor` label that depends on SAT, income, and group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a897b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5000\n",
    "\n",
    "# Group label: 0 = disadvantaged, 1 = advantaged\n",
    "group = np.random.binomial(1, 0.5, size=n)\n",
    "\n",
    "# Income: log-normal-ish, higher for advantaged group\n",
    "base_income = np.random.lognormal(mean=10, sigma=0.5, size=n)  # around ~22k\n",
    "income_multiplier = np.where(group == 1, 3.0, 1.0)  # advantaged ~3x richer\n",
    "family_income = base_income * income_multiplier\n",
    "\n",
    "# SAT: normal distributions with different means by group\n",
    "sat_mean_disadv = 1050\n",
    "sat_mean_adv = 1300\n",
    "\n",
    "sat_score = np.where(\n",
    "    group == 1,\n",
    "    np.random.normal(loc=sat_mean_adv, scale=80, size=n),\n",
    "    np.random.normal(loc=sat_mean_disadv, scale=90, size=n)\n",
    ")\n",
    "\n",
    "# Clip SAT to valid range 400â€“1600\n",
    "sat_score = np.clip(sat_score, 400, 1600)\n",
    "\n",
    "# Introduce a few extreme outliers (e.g., data issues or anomalies)\n",
    "num_outliers = 20\n",
    "outlier_indices = np.random.choice(n, size=num_outliers, replace=False)\n",
    "sat_score[outlier_indices[:10]] = 200   # unrealistically low\n",
    "sat_score[outlier_indices[10:]] = 1800  # unrealistically high\n",
    "\n",
    "# Donor label: logistic function of SAT, income, and group\n",
    "sat_scaled = (sat_score - 1000) / 400.0\n",
    "income_scaled = np.log1p(family_income) / 13.0\n",
    "\n",
    "logit = -3.0 + 1.2 * sat_scaled + 2.5 * income_scaled + 0.5 * group\n",
    "prob_donor = 1 / (1 + np.exp(-logit))\n",
    "future_donor = np.random.binomial(1, prob_donor)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'sat_score': sat_score,\n",
    "    'family_income': family_income,\n",
    "    'group': group,\n",
    "    'future_donor': future_donor\n",
    "})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b0d9c6",
   "metadata": {},
   "source": [
    "## 2. Explore SAT Distribution and Detect Outliers\n",
    "\n",
    "We treat SAT outliers in two ways here:\n",
    "1. **Rule-based bounds**: SAT should be between 400 and 1600. Values outside are almost certainly errors.\n",
    "2. **Statistical bounds**: using the IQR rule to flag extreme values, even if within the valid range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc546464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of SAT scores\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(df['sat_score'], bins=40)\n",
    "plt.xlabel('SAT score')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of SAT Scores (with simulated outliers)')\n",
    "plt.show()\n",
    "\n",
    "# Simple rule-based outlier flags\n",
    "df['sat_out_of_range'] = (df['sat_score'] < 400) | (df['sat_score'] > 1600)\n",
    "print('Number of SAT scores outside [400, 1600]:', df['sat_out_of_range'].sum())\n",
    "\n",
    "# IQR-based outlier detection (within-range extremes)\n",
    "q1 = df['sat_score'].quantile(0.25)\n",
    "q3 = df['sat_score'].quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "lower_bound = q1 - 1.5 * iqr\n",
    "upper_bound = q3 + 1.5 * iqr\n",
    "\n",
    "df['sat_iqr_outlier'] = (df['sat_score'] < lower_bound) | (df['sat_score'] > upper_bound)\n",
    "print('Number of IQR-based SAT outliers:', df['sat_iqr_outlier'].sum())\n",
    "print('Lower bound:', lower_bound, 'Upper bound:', upper_bound)\n",
    "\n",
    "df[['sat_score', 'sat_out_of_range', 'sat_iqr_outlier']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9885bb",
   "metadata": {},
   "source": [
    "## 3. Baseline Model Using All Data\n",
    "\n",
    "We now train a simple logistic regression model to predict `future_donor` using:\n",
    "- SAT score (standardized)\n",
    "- log-transformed family income\n",
    "- group (0/1)\n",
    "\n",
    "We then compute overall performance and simple group fairness metrics:\n",
    "- Accuracy overall\n",
    "- Positive prediction rate by group\n",
    "- True positive rate (TPR) by group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420ebb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['log_income'] = np.log1p(df['family_income'])\n",
    "\n",
    "features = ['sat_score', 'log_income', 'group']\n",
    "X = df[features]\n",
    "y = df['future_donor']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "\n",
    "model_all = LogisticRegression(max_iter=1000)\n",
    "model_all.fit(X_train, y_train)\n",
    "\n",
    "y_pred_all = model_all.predict(X_test)\n",
    "y_prob_all = model_all.predict_proba(X_test)[:, 1]\n",
    "\n",
    "acc_all = accuracy_score(y_test, y_pred_all)\n",
    "cm_all = confusion_matrix(y_test, y_pred_all)\n",
    "acc_all, cm_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b5fe83",
   "metadata": {},
   "source": [
    "### 3.1. Basic Fairness Metrics by Group\n",
    "\n",
    "We define helper functions to compute:\n",
    "- Positive prediction rate (PPR)\n",
    "- True positive rate (TPR)\n",
    "for each group (0 = disadvantaged, 1 = advantaged)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e2a171",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_metrics(y_true, y_pred, group_test, group_value):\n",
    "    mask = group_test == group_value\n",
    "    y_t = y_true[mask]\n",
    "    y_p = y_pred[mask]\n",
    "    \n",
    "    if len(y_t) == 0:\n",
    "        return {'ppr': np.nan, 'tpr': np.nan}\n",
    "    \n",
    "    # Positive prediction rate\n",
    "    ppr = (y_p == 1).mean()\n",
    "    \n",
    "    # True positive rate\n",
    "    tp = np.sum((y_t == 1) & (y_p == 1))\n",
    "    fn = np.sum((y_t == 1) & (y_p == 0))\n",
    "    tpr = tp / (tp + fn) if (tp + fn) > 0 else np.nan\n",
    "    \n",
    "    return {'ppr': ppr, 'tpr': tpr}\n",
    "\n",
    "group_test = X_test['group'].values\n",
    "\n",
    "metrics_all_g0 = group_metrics(y_test.values, y_pred_all, group_test, 0)\n",
    "metrics_all_g1 = group_metrics(y_test.values, y_pred_all, group_test, 1)\n",
    "\n",
    "print('Overall accuracy (all data):', acc_all)\n",
    "print('\\nGroup 0 (disadvantaged):', metrics_all_g0)\n",
    "print('Group 1 (advantaged):   ', metrics_all_g1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d57f524",
   "metadata": {},
   "source": [
    "## 4. Model After Removing SAT Outliers\n",
    "\n",
    "Now we **remove SAT outliers** (using IQR-based detection) and retrain the model.\n",
    "We then compare performance and fairness metrics to the baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ac92d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out IQR-based SAT outliers\n",
    "df_no_outliers = df[~df['sat_iqr_outlier']].copy()\n",
    "df_no_outliers['log_income'] = np.log1p(df_no_outliers['family_income'])\n",
    "\n",
    "X2 = df_no_outliers[features]\n",
    "y2 = df_no_outliers['future_donor']\n",
    "\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(\n",
    "    X2, y2, test_size=0.3, stratify=y2, random_state=42\n",
    ")\n",
    "\n",
    "model_no = LogisticRegression(max_iter=1000)\n",
    "model_no.fit(X2_train, y2_train)\n",
    "\n",
    "y2_pred = model_no.predict(X2_test)\n",
    "y2_prob = model_no.predict_proba(X2_test)[:, 1]\n",
    "\n",
    "acc_no = accuracy_score(y2_test, y2_pred)\n",
    "cm_no = confusion_matrix(y2_test, y2_pred)\n",
    "acc_no, cm_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8315023f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fairness metrics after removing outliers\n",
    "group2_test = X2_test['group'].values\n",
    "\n",
    "metrics_no_g0 = group_metrics(y2_test.values, y2_pred, group2_test, 0)\n",
    "metrics_no_g1 = group_metrics(y2_test.values, y2_pred, group2_test, 1)\n",
    "\n",
    "print('Overall accuracy (no SAT outliers):', acc_no)\n",
    "print('\\nGroup 0 (disadvantaged):', metrics_no_g0)\n",
    "print('Group 1 (advantaged):   ', metrics_no_g1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d17ba0",
   "metadata": {},
   "source": [
    "## 5. Comparing Performance and Fairness\n",
    "\n",
    "We now compare the **baseline model** (all data) versus the **no-outlier model**:\n",
    "- Changes in overall accuracy\n",
    "- Changes in PPR (Positive Prediction Rate) by group\n",
    "- Changes in TPR (True Positive Rate) by group\n",
    "\n",
    "In a real institutional setting, we would discuss whether removing outliers makes the model more or less fair,\n",
    "and whether it disproportionately helps or harms a particular group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5658b26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.DataFrame({\n",
    "    'model': ['all_data', 'no_outliers'],\n",
    "    'accuracy': [acc_all, acc_no],\n",
    "    'g0_ppr': [metrics_all_g0['ppr'], metrics_no_g0['ppr']],\n",
    "    'g0_tpr': [metrics_all_g0['tpr'], metrics_no_g0['tpr']],\n",
    "    'g1_ppr': [metrics_all_g1['ppr'], metrics_no_g1['ppr']],\n",
    "    'g1_tpr': [metrics_all_g1['tpr'], metrics_no_g1['tpr']]\n",
    "})\n",
    "\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57aa7e35",
   "metadata": {},
   "source": [
    "## 6. Interpretation\n",
    "\n",
    "Use the table above to discuss:\n",
    "\n",
    "1. **Performance impact**: Did removing SAT outliers significantly change accuracy?\n",
    "2. **Fairness impact**: How did PPR and TPR change for group 0 vs. group 1?\n",
    "   - If the disparity between groups shrinks, removing outliers may have improved fairness.\n",
    "   - If the disparity grows, removing outliers may have unintentionally harmed fairness.\n",
    "\n",
    "3. **Ethical implications**:\n",
    "   - Are SAT outliers mostly coming from advantaged or disadvantaged groups in our simulation?\n",
    "   - Would removing them erase legitimate high (or low) performance from certain students?\n",
    "   - In a real dataset, outliers could represent errors, rare but real talent, or structural inequality.\n",
    "\n",
    "This notebook is a starting point: in practice you would add more robust fairness metrics\n",
    "(e.g., equalized odds, demographic parity), multiple models, and sensitivity analyses\n",
    "before making any policy decisions about how to handle SAT outliers."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
